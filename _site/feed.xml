<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>alvaro carril blog</title>
    <description>Blog on the tools of the trade of the econ research analyst.</description>
    <link>http://acarril.github.io/</link>
    <atom:link href="http://acarril.github.io/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Tue, 10 May 2016 18:51:35 -0300</pubDate>
    <lastBuildDate>Tue, 10 May 2016 18:51:35 -0300</lastBuildDate>
    <generator>Jekyll v2.4.0</generator>
    
      <item>
        <title>psestimate</title>
        <description>&lt;p&gt;&lt;strong&gt;psestimate&lt;/strong&gt;&lt;/p&gt;
</description>
        <pubDate>Tue, 10 May 2016 00:00:00 -0300</pubDate>
        <link>http://acarril.github.io/posts/psestimate</link>
        <guid isPermaLink="true">http://acarril.github.io/posts/psestimate</guid>
        
        
      </item>
    
      <item>
        <title>Deleting values from macro</title>
        <description>&lt;p&gt;After defining a macro, specially inside a program, I have found that oftentimes I need to update its content by eliminating one of its values. In this post I explain how to easily do it.&lt;/p&gt;

&lt;h1 id=&quot;setup&quot;&gt;Setup&lt;/h1&gt;

&lt;p&gt;Suppose you define the contents of a local macro &lt;code&gt;vars&lt;/code&gt; as&lt;/p&gt;

&lt;pre class=&quot;sh_stata&quot;&gt;
local vars a b c d e
&lt;/pre&gt;

&lt;h1 id=&quot;solution-with-macro-lists&quot;&gt;Solution with macro lists&lt;/h1&gt;

&lt;p&gt;Now, for some reason, I need to update the contents of &lt;code&gt;vars&lt;/code&gt; by eliminating the value &lt;code&gt;c&lt;/code&gt;. The easiest way to do it is using &lt;a href=&quot;http://www.stata.com/manuals13/pmacrolists.pdf&quot;&gt;macro lists&lt;/a&gt;:&lt;/p&gt;

&lt;pre class=&quot;sh_stata&quot;&gt;
local not c
local vars: list vars - not
di &quot;`vars&#39;&quot;
&lt;/pre&gt;

&lt;p&gt;Cool! No need to &lt;a href=&quot;http://www.stata.com/manuals13/ptokenize.pdf&quot;&gt;tokenize&lt;/a&gt;.&lt;/p&gt;
</description>
        <pubDate>Thu, 05 May 2016 00:00:00 -0300</pubDate>
        <link>http://acarril.github.io/posts/delete-values-macro</link>
        <guid isPermaLink="true">http://acarril.github.io/posts/delete-values-macro</guid>
        
        
        <category>stata</category>
        
      </item>
    
      <item>
        <title>R-squared in quantile regressions</title>
        <description>&lt;p&gt;We know that &lt;script type=&quot;math/tex&quot;&gt;R^2&lt;/script&gt; is not relevant to quantile regression. In this post I explain why is that so and how can we measure “goodness of fit” using alternative measurements.&lt;/p&gt;

&lt;h1 id=&quot;basics-of-quantile-regression-models&quot;&gt;Basics of quantile regression models&lt;/h1&gt;

&lt;p&gt;Quantile regression models (QRM) are&lt;/p&gt;

&lt;h1 id=&quot;measuring-goodness-of-fit&quot;&gt;Measuring goodness of fit&lt;/h1&gt;

&lt;p&gt;&lt;a href=&quot;http://ajbuckeconbikesail.net/Econ616/Quantile/JASA1999.pdf&quot;&gt;Koenker and Machado (1999)&lt;/a&gt; propose &lt;script type=&quot;math/tex&quot;&gt;R^1(\tau)&lt;/script&gt;, a pseudo-&lt;script type=&quot;math/tex&quot;&gt;R^2&lt;/script&gt; which measures goodness of fit by comparing the sum of weighted deviations for the model of interest at the &lt;script type=&quot;math/tex&quot;&gt;\tau&lt;/script&gt; quantile with the same sum from a model in which only the intercept appears.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
R_1(\tau) = 1 - \frac{\sum_{y_i \ge \hat y_i} \tau \cdot \vert y_i-\hat y_i \vert +\sum_{y_i&lt;\hat y_i} (1-\tau) \cdot \vert y_i-\hat y_i \vert}{\sum_{y_i \ge \bar y} \tau \cdot \vert y_i-\bar y \vert +\sum_{y_i&lt;\bar y_i} (1-\tau) \cdot \vert y_i-\bar y \vert}, %]]&gt;&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;\hat y_i =\alpha_{\tau}+\beta_{\tau}x&lt;/script&gt; is the fitted &lt;script type=&quot;math/tex&quot;&gt;\tau&lt;/script&gt;th quantile for observation &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt;, and &lt;script type=&quot;math/tex&quot;&gt;\bar y=\beta_{\tau}&lt;/script&gt; is the fitted value from the intercept-only model. &lt;script type=&quot;math/tex&quot;&gt;R_1(\tau)&lt;/script&gt; belongs to &lt;script type=&quot;math/tex&quot;&gt;[0,1]&lt;/script&gt;, where 1 is a perfect fit, since the numerator (weighted sum of deviations) would be zero in such case.&lt;/p&gt;

&lt;p&gt;Note that this is a &lt;em&gt;local&lt;/em&gt; measure of fit for QRM since it depends on &lt;script type=&quot;math/tex&quot;&gt;\tau&lt;/script&gt;, unlike the global &lt;script type=&quot;math/tex&quot;&gt;R^2&lt;/script&gt; from OLS. That is arguably the source of the warnings about using it: if you model fits in the tail, there’s not guarantee that it fits well anywhere else.&lt;br /&gt;
This approach could also be used to compare nested models.&lt;/p&gt;
</description>
        <pubDate>Sun, 01 May 2016 00:00:00 -0300</pubDate>
        <link>http://acarril.github.io/posts/QRM-r-squared</link>
        <guid isPermaLink="true">http://acarril.github.io/posts/QRM-r-squared</guid>
        
        
        <category>econ</category>
        
      </item>
    
      <item>
        <title>Running sections of do-files</title>
        <description>&lt;p&gt;As do-files get larger and more complex, it is common to want to run only a portion or section of the code. Over the years I’ve come to use extensively what I call &lt;strong&gt;do-switches&lt;/strong&gt;, which are just handy devices for “turning on and off” some parts of the code.&lt;/p&gt;

&lt;h1 id=&quot;the-issue&quot;&gt;The issue&lt;/h1&gt;

&lt;p&gt;We’ve all done it. It starts with&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Error! &lt;code&gt;r(XXX);&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;then&lt;br /&gt;
  &amp;lt;ol start=&quot;2&quot;&amp;gt;&lt;br /&gt;
    &amp;lt;li&amp;gt;Correct small portion of code&amp;lt;/li&amp;gt;&lt;br /&gt;
    &amp;lt;li&amp;gt;&lt;b&gt;Select section of code in large do-file and run it&lt;/b&gt;&amp;lt;/li&amp;gt;&lt;br /&gt;
    &lt;i&gt;(rinse and repeat)&lt;/i&gt;&lt;br /&gt;
  &amp;lt;/ol&amp;gt;&lt;/p&gt;

&lt;p&gt;This post is all about step &lt;strong&gt;3.&lt;/strong&gt;, which is can be very graphically appreciated in the following gif:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../files/long_selection.gif&quot; alt=&quot;Long selection&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;enter-do-switches&quot;&gt;Enter do-switches&lt;/h1&gt;

&lt;p&gt;The idea is extremely simple: just set a local to 1 if you want to run some section of the code, and 0 (or anything else) otherwise. Then you can enclose the sections of codes you want to switch “on and off” with conditional blocks.&lt;/p&gt;

&lt;p&gt;For example, suppose we have a do-file that imports several datasets and then merges them. We could structure this with the following code:&lt;/p&gt;

&lt;pre class=&quot;sh_stata&quot;&gt;
local A     0
local B     0
local merge 0

if `A&#39; == 1 {
  * Import and save A
}

if `B&#39; == 1 {
  * Import and save B
}

if `merge&#39; == 1 {
  * Merge A with B and save
}
&lt;/pre&gt;
</description>
        <pubDate>Wed, 20 Apr 2016 00:00:00 -0300</pubDate>
        <link>http://acarril.github.io/posts/dofile-section</link>
        <guid isPermaLink="true">http://acarril.github.io/posts/dofile-section</guid>
        
        
        <category>stata</category>
        
      </item>
    
      <item>
        <title>Parallel processes in batch mode</title>
        <description>&lt;p&gt;One of the most powerful features of batch mode is the ability to run several processes in parallel. I’ll explain how to easily use this feature  with Stata.&lt;/p&gt;

&lt;p&gt;This is the second post regarding batch jobs in the RCE server. I also wrote a &lt;a href=&quot;batch-jobs&quot;&gt;first part&lt;/a&gt; which deals with the basics of running batch jobs using Stata.&lt;/p&gt;

&lt;h1 id=&quot;stuff-needed&quot;&gt;Stuff needed&lt;/h1&gt;

&lt;p&gt;We are going to need, as usual, a &lt;a href=&quot;#do-file&quot;&gt;&lt;strong&gt;do-file&lt;/strong&gt;&lt;/a&gt; and a &lt;a href=&quot;#submit-file&quot;&gt;&lt;strong&gt;submit file&lt;/strong&gt;&lt;/a&gt;. We are also going to assume some basic &lt;a href=&quot;#directory-structure&quot;&gt;&lt;strong&gt;directory structure&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;directory-structure&quot;&gt;Directory structure&lt;/h3&gt;

&lt;p&gt;For this example we’ll need to set everything up in a root folder which contains a &lt;code&gt;dofiles&lt;/code&gt; folder, a &lt;code&gt;batch_output&lt;/code&gt; folder and a &lt;code&gt;datasets&lt;/code&gt; folder. The do-file to submit is going to be located inside the dofiles folder, while the submit file is located in the root folder. All this can be easily seen in the screenshot below.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;..\files\batch_process_directory_structure.png&quot; alt=&quot;batch_process_directory_structure&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;do-file&quot;&gt;Do-file&lt;/h3&gt;

&lt;p&gt;The do-file we’re using is going to&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Always read the same dataset&lt;/li&gt;
  &lt;li&gt;Set a different seed for each process&lt;/li&gt;
  &lt;li&gt;Extract a different sample with replacement for each process&lt;/li&gt;
  &lt;li&gt;Compute the average value of a variable from the sampled observations for each process&lt;/li&gt;
  &lt;li&gt;Save a different collapsed dataset for each process&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The key here is to collect &lt;code&gt;process&lt;/code&gt;, an integer passed by the submit file (see the &lt;a href=&quot;#submit-file&quot;&gt;submit file&lt;/a&gt; below) onto the do-file. This will make each run of the do-file unique for each process.&lt;/p&gt;

&lt;pre class=&quot;sh_stata&quot;&gt;
// set more off so that the do-file runs without halting
set more off

// collect the arguments passed by submit file
args process

// load example dataset
sysuse bpwide, clear

// set seed so it&#39;s different for every process
set seed `process&#39;

// sample with replacement
bsample, cluster(patient) idcluster(idcluster)

// calculate the mean and standard deviation
collapse (mean) mean_bp_before = bp_before (sd) sd_bp_before = bp_before

// save the result, appending the process number to the dataset name
save &quot;datasets/output_`process&#39;.dta&quot;, replace
&lt;/pre&gt;

&lt;h3 id=&quot;submit-file&quot;&gt;Submit file&lt;/h3&gt;

&lt;p&gt;The submit file is very similar to the basic template, but now we pass the &lt;code&gt;Process&lt;/code&gt; argument from the batch system onto Stata, by defining a global (remeber our do-file expects that?). The way to do that is by appending &lt;code&gt;$(Process)&lt;/code&gt; at the end of the &lt;code&gt;Arguments&lt;/code&gt; line. The process number should also be appended to the &lt;code&gt;ouptut&lt;/code&gt;, &lt;code&gt;error&lt;/code&gt; and &lt;code&gt;log&lt;/code&gt; files, like below.&lt;/p&gt;

&lt;p&gt;How many process we are requesting is defined in the last line, &lt;code&gt;Queue&lt;/code&gt;. In this example we’re requesting 10 processes, which will make the &lt;code&gt;$(Process)&lt;/code&gt; integer go from 0 to 9.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-c&quot;&gt;Universe = vanilla
Executable = /usr/local/bin/stata-mp

# Pass the process number, which will be used
# to append the process number to the output files.
Arguments = -q do dofiles/batch_process.do $(Process)

output = batch_output/mydofile$(Process).out
error = batch_output/mydofile$(Process).err
Log = batch_output/mydofile$(Process).log

Request_Cpus = 2
Request_Memory = 2GB

# Notifications settings
notification = Always
notify_user = your@email.com

# Number of processes to request
Queue 10
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&quot;running-the-processes&quot;&gt;Running the processes&lt;/h1&gt;

&lt;p&gt;To submit these parallel jobs we’ll go to the command line and change the current directory to our root folder. For example, I have put all the files of this example in a folder called &lt;code&gt;batch&lt;/code&gt;, located inside my personal directory in the RCE environment, so I use&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cd batch
condor_submit stata_batch_process.submit
&lt;/code&gt;&lt;/pre&gt;
</description>
        <pubDate>Wed, 20 Apr 2016 00:00:00 -0300</pubDate>
        <link>http://acarril.github.io/posts/batch-processes</link>
        <guid isPermaLink="true">http://acarril.github.io/posts/batch-processes</guid>
        
        
        <category>rce</category>
        
      </item>
    
      <item>
        <title>Batch Jobs</title>
        <description>&lt;p&gt;Running a job in batch mode is extremely useful for performing long processes in the background, while freeing the GUI interface for other tasks. Even though a particular Stata task is not performed faster in batch mode, it allows to perform several tasks in parallel.&lt;/p&gt;

&lt;p&gt;In this post I explain the basics of running batch jobs with Stata. I also wrote a &lt;a href=&quot;batch-processes&quot;&gt;second part&lt;/a&gt; which deals with running multiple processes in parallel.&lt;/p&gt;

&lt;h1 id=&quot;what-do-i-need&quot;&gt;What do I need?&lt;/h1&gt;

&lt;h3 id=&quot;a-do-file&quot;&gt;A do-file&lt;/h3&gt;
&lt;p&gt;First of all you need a do-file to submit. In this example we’ll submit &lt;code&gt;mydofile.do&lt;/code&gt;. The do-file hasn’t have to have anything special (at least at first).&lt;/p&gt;

&lt;h3 id=&quot;a-submit-file&quot;&gt;A submit file&lt;/h3&gt;
&lt;p&gt;You’ll need a &lt;code&gt;submit file&lt;/code&gt;, which is a simple text file with instructions on how the batch process should be run. &lt;strong&gt;The submit file has to be saved with a &lt;code&gt;*.submit&lt;/code&gt; extension.&lt;/strong&gt; So, for example, I’ll name mine &lt;code&gt;mybatch.submit&lt;/code&gt; (again, creative).&lt;/p&gt;

&lt;p&gt;The easiest way to get going is to copy the following text in any plain text editor and then make sure to save it with &lt;code&gt;*.submit&lt;/code&gt; extension (not &lt;code&gt;*.submit.txt&lt;/code&gt;!). All lines starting with a &lt;code&gt;#&lt;/code&gt; are comments. Edit what you want and save the file in the same folder as your do-file.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-c&quot;&gt;# Universe whould always be &#39;vanilla&#39;. This line MUST be
#included in your submit file, exactly as shown below.
Universe = vanilla

# The path to Stata (could be R or Matlab)
Executable = /usr/local/bin/stata-mp

# Specify any arguments you want to pass to the executable.
# Here we pass arguments to make Stata run the bootstrap.do
# file. We also pass the process number, which will be used
# to append the process number to the output files.
Arguments = -q do mydofile.do

# Specify where to output any results printed by your program.
output = output/mydofile.out
# Specify where to save any errors returned by your program.
error = output/mydofile.err
# Specify where to save the log file.
Log = output/mydofile.log

# Request processors (Stata maxes out at 4) and memory (in GB)
Request_Cpus = 4
Request_Memory = 8GB

# Notifications settings
notification = Always
notify_user = your@email.com

# Enter the number of processes to request.
# This section should always come last.
Queue 1
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;directory-structure&quot;&gt;Directory structure&lt;/h3&gt;

&lt;p&gt;Both the &lt;code&gt;do-file&lt;/code&gt; and the &lt;code&gt;submit file&lt;/code&gt; should be placed on a directory of your choosing, which we’ll call the &lt;code&gt;root directory&lt;/code&gt;. It is recommended to have a dedicated folder for the outputs produced by the batch processing system inside the &lt;code&gt;root directory&lt;/code&gt;. In this example I’ve been exceedingly creative and named that folder &lt;code&gt;/output&lt;/code&gt;.&lt;/p&gt;

&lt;h1 id=&quot;submitting-a-batch-job&quot;&gt;Submitting a batch job&lt;/h1&gt;

&lt;p&gt;Now that everything is set up, the process is really easy. You’ll need to start the command line and change directory to the &lt;code&gt;root directory&lt;/code&gt;. For example,&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cd /nfs/projects/t/tpricing
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Once there, the process is submitted with the &lt;code&gt;condor_submit &amp;lt;submit file&amp;gt;.submit&lt;/code&gt; command. For example,&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ condor_submit mybatch.submit
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It will then say that the job is submitted to a cluster number.&lt;/p&gt;

&lt;h1 id=&quot;checking-the-process&quot;&gt;Checking the process&lt;/h1&gt;

&lt;p&gt;You can check at anytime how all your submitted processes are going by typing &lt;code&gt;condor_q &amp;lt;username&amp;gt;&lt;/code&gt;. For example,&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ condor_q acarril2
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The most important column in there is &lt;code&gt;ST&lt;/code&gt;, shorthand for “Status”. If it says &lt;code&gt;R&lt;/code&gt;, then it is running. &lt;strong&gt;If you don’t see your process, then that means it has finished.&lt;/strong&gt; If that is the case, go to your &lt;code&gt;/output&lt;/code&gt; folder and check your results in the &lt;code&gt;*.out&lt;/code&gt; file.&lt;/p&gt;

&lt;p&gt;Better than checking incessantly, make sure you add your email address to the &lt;code&gt;submit file&lt;/code&gt;, so you get notified in your inbox when your job completes (or crashes)!&lt;/p&gt;
</description>
        <pubDate>Tue, 19 Apr 2016 00:00:00 -0300</pubDate>
        <link>http://acarril.github.io/posts/batch-jobs</link>
        <guid isPermaLink="true">http://acarril.github.io/posts/batch-jobs</guid>
        
        
        <category>rce</category>
        
      </item>
    
      <item>
        <title>Adding column percentages of sums to tabstat</title>
        <description>&lt;p&gt;Tabstat is a very useful command to produce tables of various summary statistics. It also works seamlessly with estout, so this tables can be easily exported.&lt;/p&gt;

&lt;p&gt;Suppose we have a dataset with information of 10 different companies over the a range of years. You can load this (fake) dataset using&lt;/p&gt;

&lt;pre class=&quot;sh_stata&quot;&gt;
. use http://www.stata-press.com/data/r14/grunfeld, clear
&lt;/pre&gt;

&lt;p&gt;We want to produce a table that sums all investments made so far by each firm and then export it. We can easily achieve that combining tabstat with estttab, producing the following result:&lt;/p&gt;

&lt;pre class=&quot;sh_stata&quot;&gt;
. estpost tabstat invest, by(company) stat(sum)
. esttab, cell(sum)
-------------------------
                      (1)
                      sum
-------------------------
1                 12160.4
2                  8209.5
3                  2045.8
4                 1722.47
5                 1236.05
6                 1108.22
7                  951.91
8                  857.83
9                  837.78
10                  61.69
Total            29191.65
-------------------------
N                     200
-------------------------
&lt;/pre&gt;

&lt;p&gt;Now suppose we want column percentages of those sums. Unfortunately, tabstat doesn’t have an option for asking that statistic, but we can manually construct it and add it to our stored estimates using estadd:&lt;/p&gt;

&lt;pre class=&quot;sh_stata&quot;&gt;
. eststo: estpost tabstat invest, by(company) stat(sum)

. matrix colupct = e(sum) // create matrix with sums
. scalar c = colsof(colupct) // create scalar with number of rows of matrix
. matrix colupct = 100*colupct/colupct[1,c] // transorm matrix values to percentages
. estadd matrix colupct = colupct // add matrix &#39;colupct&#39; to stored estimates

. esttab, cell(sum colupct)
-------------------------
                      (1)

              sum/colupct
-------------------------
1                 12160.4
                 41.65712
2                  8209.5
                 28.12277
3                  2045.8
                 7.008168
4                 1722.47
                 5.900557
5                 1236.05
                 4.234259
6                 1108.22
                  3.79636
7                  951.91
                 3.260898
8                  857.83
                 2.938614
9                  837.78
                  2.86993
10                  61.69
                 .2113276
Total            29191.65
                      100
-------------------------
N                     200
-------------------------
&lt;/pre&gt;

&lt;p&gt;Finally, it is probably nicer to present those percentages with only one decimal and inside parenthesis. We can do this by adding the necessary options to esttab:&lt;/p&gt;

&lt;pre class=&quot;sh_stata&quot;&gt;
. eststo clear // clear previously stored estimates
. esttab, cell(sum colupct(fmt(1) par))
-------------------------
                      (1)

              sum/colupct
-------------------------
1                 12160.4
                   (41.7)
2                  8209.5
                   (28.1)
3                  2045.8
                    (7.0)
4                 1722.47
                    (5.9)
5                 1236.05
                    (4.2)
6                 1108.22
                    (3.8)
7                  951.91
                    (3.3)
8                  857.83
                    (2.9)
9                  837.78
                    (2.9)
10                  61.69
                    (0.2)
Total            29191.65
                  (100.0)
-------------------------
N                     200
-------------------------
&lt;/pre&gt;
</description>
        <pubDate>Mon, 11 Apr 2016 00:00:00 -0300</pubDate>
        <link>http://acarril.github.io/posts/column-percentages-tabstat</link>
        <guid isPermaLink="true">http://acarril.github.io/posts/column-percentages-tabstat</guid>
        
        
        <category>stata</category>
        
      </item>
    
      <item>
        <title>On the probability of false positives</title>
        <description>&lt;p&gt;Whenever we do regression analysis there is the chance of getting false positives. Suppose you have &lt;script type=&quot;math/tex&quot;&gt;k&lt;/script&gt; outcome variables and are targeting a &lt;script type=&quot;math/tex&quot;&gt;p&lt;/script&gt;-value of &lt;script type=&quot;math/tex&quot;&gt;p&lt;/script&gt;. Is there a way to compute &lt;em&gt;ex ante&lt;/em&gt; the exact probability of getting at least one false positive significant result under &lt;script type=&quot;math/tex&quot;&gt;p&lt;/script&gt;?&lt;/p&gt;

&lt;p&gt;This question arose during a discussion with a J-PAL colleague. Since we were talking about randomized control trials, he also considered a treatment group of size &lt;script type=&quot;math/tex&quot;&gt;m&lt;/script&gt; and a control group of size &lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;But does it matter?&lt;/p&gt;

&lt;p&gt;Assuming i.i.d. Normal characteristics we can use separate &lt;a href=&quot;https://en.wikipedia.org/wiki/Welch%27s_t_test&quot;&gt;Welch’s &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt;-tests&lt;/a&gt;, which account for different variances and sample sizes. If the statistics of these tests are &lt;script type=&quot;math/tex&quot;&gt;w_i&lt;/script&gt; (&lt;script type=&quot;math/tex&quot;&gt;i=1,..., k&lt;/script&gt;), the &lt;script type=&quot;math/tex&quot;&gt;p&lt;/script&gt;-value of each one is&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;$$ p_i = \Pr(&lt;/td&gt;
      &lt;td&gt;w_i&lt;/td&gt;
      &lt;td&gt;\geq w(\alpha)\mid H_0),$$&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;H_0&lt;/script&gt; is the null hypothesis&lt;!--- of equal means of the control and treatment groups--&gt;.&lt;/p&gt;

&lt;p&gt;The above probability can be expressed in terms of the corresponding cumulative distribution function, that is, &lt;script type=&quot;math/tex&quot;&gt;\Pr (\cdot)=1-F( \mid w_i \mid )&lt;/script&gt; . Therefore we have that&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;$$F(&lt;/td&gt;
      &lt;td&gt;w_i&lt;/td&gt;
      &lt;td&gt;)=1-p_i .$$&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The key here is thinking of &lt;script type=&quot;math/tex&quot;&gt;p&lt;/script&gt;-values as random variables and, because of the magic of &lt;a href=&quot;https://en.wikipedia.org/wiki/Probability_integral_transform&quot;&gt;probability integral transform&lt;/a&gt;, we know that &lt;script type=&quot;math/tex&quot;&gt;(1-p_i)&lt;/script&gt; distributes uniformly, so we get&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt; p_i\sim U(0,1).&lt;/script&gt;

&lt;p&gt;Now we have a sample size of &lt;script type=&quot;math/tex&quot;&gt;k&lt;/script&gt; independent uniform distributions. The probability that at least one of them is smaller than a specific value &lt;script type=&quot;math/tex&quot;&gt;\overline p&lt;/script&gt; is equal to the probability that the minimum of them is lower than that threshold, that is,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt; \Pr(\text{At least one }p_i \leq \overline p) = 1- \Pr (\text{All }p_i &gt; \overline p ) = 1- \prod_{i=1}^k \Pr (p_i &gt; p^*).&lt;/script&gt;

&lt;p&gt;Since all &lt;script type=&quot;math/tex&quot;&gt;p_i&lt;/script&gt; are identically distributed, we have that&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt; \Pr(\text{At least one }p_i \leq \overline p) = 1-[1-\Pr(p_i\leq\overline p)]^k = 1-[1-F_U(\overline p)]^k,&lt;/script&gt;

&lt;p&gt;which is the &lt;a href=&quot;https://en.wikipedia.org/wiki/Cumulative_distribution_function&quot;&gt;cumulative distribution function&lt;/a&gt; (CDF) of the minimum of &lt;script type=&quot;math/tex&quot;&gt;k&lt;/script&gt; i.i.d. random variables.&lt;/p&gt;

&lt;p&gt;Let’s say this minimum is &lt;script type=&quot;math/tex&quot;&gt;p_{min}&lt;/script&gt;, then the CDF of the minimum of &lt;script type=&quot;math/tex&quot;&gt;k&lt;/script&gt; independent &lt;script type=&quot;math/tex&quot;&gt;U(0,1)&lt;/script&gt; variables is&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt; F_{p_{min}}(p_{min}) = 1- [1-p_{min}]^k.&lt;/script&gt;

&lt;p&gt;Therefore we want to know the probability&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt; \Pr (p_{min}\leq \overline p) = 1-[1-p_{min}]^k. &lt;/script&gt;

&lt;p&gt;So it is interesting to note that the probability of getting at least one false positive significant result under &lt;script type=&quot;math/tex&quot;&gt;p&lt;/script&gt; doesn’t depend on the size of treatment nor control groups (in an impact evaluation setting), or even on sample size. Because &lt;script type=&quot;math/tex&quot;&gt;p&lt;/script&gt;-values are random variables, they are uniformly distributed &lt;script type=&quot;math/tex&quot;&gt;(0,1)&lt;/script&gt; regardless of sample size.*&lt;/p&gt;

&lt;p&gt;To get an idea of some typical values of our last formula, here is a table:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[

\begin{array}{rr|lllll}
  &amp;    &amp;       &amp;       &amp; p     &amp;       &amp;       \\
  &amp;    &amp; 0.001 &amp; 0.005 &amp; 0.01  &amp; 0.05  &amp; 0.1   \\\hline
  &amp; 1  &amp; 0.001 &amp; 0.005 &amp; 0.010 &amp; 0.050 &amp; 0.100 \\
  &amp; 2  &amp; 0.002 &amp; 0.010 &amp; 0.020 &amp; 0.098 &amp; 0.190 \\
  &amp; 3  &amp; 0.003 &amp; 0.015 &amp; 0.030 &amp; 0.143 &amp; 0.271 \\
  &amp; 4  &amp; 0.004 &amp; 0.020 &amp; 0.039 &amp; 0.185 &amp; 0.344 \\
  &amp; 5  &amp; 0.005 &amp; 0.025 &amp; 0.049 &amp; 0.226 &amp; 0.410 \\
k &amp; 10 &amp; 0.010 &amp; 0.049 &amp; 0.096 &amp; 0.401 &amp; 0.651 \\
  &amp; 15 &amp; 0.015 &amp; 0.072 &amp; 0.140 &amp; 0.537 &amp; 0.794 \\
  &amp; 20 &amp; 0.020 &amp; 0.095 &amp; 0.182 &amp; 0.642 &amp; 0.878 \\
  &amp; 30 &amp; 0.030 &amp; 0.140 &amp; 0.260 &amp; 0.785 &amp; 0.958 \\
  &amp; 40 &amp; 0.039 &amp; 0.182 &amp; 0.331 &amp; 0.871 &amp; 0.985 \\
  &amp; 50 &amp; 0.049 &amp; 0.222 &amp; 0.395 &amp; 0.923 &amp; 0.995
\end{array}
 %]]&gt;&lt;/script&gt;

&lt;!--![Probs table](http://i60.tinypic.com/347b48h.png)--&gt;

&lt;p&gt;* Of course, the values of &lt;script type=&quot;math/tex&quot;&gt;m&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; do enter the test-statistic. For example, if we assume that the underlying data is normally distributed i.i.d., with mean &lt;script type=&quot;math/tex&quot;&gt;\mu&lt;/script&gt; and variance &lt;script type=&quot;math/tex&quot;&gt;\sigma&lt;/script&gt; for both treatment and control groups, then it can be proven we can get the &lt;a href=&quot;https://en.wikipedia.org/wiki/Student%27s_t-test&quot;&gt;Student’s &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt;-statistic&lt;/a&gt;:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;t = \frac{\overline {X}_1 - \overline{X}_2}{s_{X_1 X_2} \cdot \sqrt{\frac{1}{m}+\frac{1}{n}}},&lt;/script&gt;

&lt;p&gt;where&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;s_{X_1X_2} = \sqrt{\frac{(m-1)s_{X_1}^2+(n-1)s_{X_2}^2}{m+n}}.&lt;/script&gt;
</description>
        <pubDate>Mon, 12 Oct 2015 00:00:00 -0300</pubDate>
        <link>http://acarril.github.io/posts/prob-false-positives</link>
        <guid isPermaLink="true">http://acarril.github.io/posts/prob-false-positives</guid>
        
        
        <category>econ</category>
        
      </item>
    
      <item>
        <title>Slutsky matrix times price vector</title>
        <description>&lt;p&gt;From microeconomic theory we know that
&lt;script type=&quot;math/tex&quot;&gt;S(p, w) \cdot p = 0,&lt;/script&gt;&lt;br /&gt;
where &lt;script type=&quot;math/tex&quot;&gt;S&lt;/script&gt; is the Slutsky matrix and &lt;script type=&quot;math/tex&quot;&gt;p&lt;/script&gt; is the price vector.&lt;/p&gt;

&lt;p&gt;Why?&lt;/p&gt;

&lt;p&gt;It is a general mathematical result that the &lt;a href=&quot;https://en.wikipedia.org/wiki/Hessian_matrix&quot;&gt;Hessian matrix&lt;/a&gt; of a multivariate function is homogeneous of degree one.&lt;/p&gt;

&lt;p&gt;But really, &lt;em&gt;why&lt;/em&gt;?&lt;/p&gt;

&lt;p&gt;We know that the &lt;strong&gt;expenditure function&lt;/strong&gt; &lt;script type=&quot;math/tex&quot;&gt;E&lt;/script&gt;  is homogeneous of degree one in prices. Intuitively, if all prices change in the same proportion then relative prices stay constant. And if relative prices stay constant, the minimum-cost compensated bundle for a given utility level also remains unchanged. That is, budget shares stay the same. So the &lt;em&gt;expenditure&lt;/em&gt; (expressed by &lt;script type=&quot;math/tex&quot;&gt;E&lt;/script&gt;)  needed to achieve the same utility level as before changes in the same proportion as prices, and so we have homogeneity of degree one.&lt;/p&gt;

&lt;p&gt;By duality, the &lt;strong&gt;Hicksian demand&lt;/strong&gt; vector is the gradient of the expenditure function on prices,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;H= \frac{d E}{d p}.&lt;/script&gt;

&lt;p&gt;Intuitively, &lt;script type=&quot;math/tex&quot;&gt;H&lt;/script&gt; gives the minimum-cost demanded quantities. Due to the homogeneity of degree one of the expenditure function, the inner product of the Hicksian demand vector times the price vector equals the expenditure function:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;H\cdot p=E.&lt;/script&gt;

&lt;p&gt;This is because we are just multiplying the (minimum-cost) demanded quantities by their unit price and then summing up, which is total expenditure.&lt;/p&gt;

&lt;p&gt;Combining these two results we have that&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{d (H\cdot p)}{dp}=H&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;H + \frac{d H}{dp}\cdot p = H.&lt;/script&gt;

&lt;p&gt;So it follows that when &lt;script type=&quot;math/tex&quot;&gt;H=0&lt;/script&gt;,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{dH}{dp}\cdot p = 0.&lt;/script&gt;

&lt;p&gt;We know that the &lt;a href=&quot;https://en.wikipedia.org/wiki/Jacobian_matrix_and_determinant&quot;&gt;Jacobian matrix&lt;/a&gt; of the Hicksian demand is the Hessian matrix of the expenditure function, that is,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{dH}{dp}=\frac{d^2E}{dp^2}=S(p,w).&lt;/script&gt;

&lt;p&gt;So using these last two results gives us that&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;S(p, w) \cdot p = 0.&lt;/script&gt;

&lt;p&gt;This means that compensated demanded quantities are not affected by changes in price if relative prices remain constant.&lt;/p&gt;
</description>
        <pubDate>Sun, 06 Sep 2015 00:00:00 -0300</pubDate>
        <link>http://acarril.github.io/posts/slutsky</link>
        <guid isPermaLink="true">http://acarril.github.io/posts/slutsky</guid>
        
        
        <category>econ</category>
        
      </item>
    
  </channel>
</rss>
